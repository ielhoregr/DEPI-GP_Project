{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "944fd70a-32cc-4ccc-9aae-ea3ef983c28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91ba481-f26f-451a-9564-47648f184ce0",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "553ff929-b6db-40e5-8635-ffd4fbb3ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train = pd.read_csv('Amazon review dataset/train.csv', header=None, names=['polarity', 'title', 'review'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afda5e4c-2a01-4e4d-8574-ed6491cb424b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1162981</th>\n",
       "      <td>2</td>\n",
       "      <td>b- lynch maaaaaaaaaaaaaaaaannn</td>\n",
       "      <td>Lynch is back in that ????????? U know what im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347597</th>\n",
       "      <td>1</td>\n",
       "      <td>LOW QUALITY VERY EARLY RECORDINGS!!!</td>\n",
       "      <td>THIS SHONGS ARE NOT THE GREATEST HITS OF THIS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512958</th>\n",
       "      <td>1</td>\n",
       "      <td>YALL MUST BE KIDDING...</td>\n",
       "      <td>ok first off, if you come by my review, let it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081008</th>\n",
       "      <td>1</td>\n",
       "      <td>surf's up...NOT</td>\n",
       "      <td>The ONLY reason that I gave this game two (2) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858731</th>\n",
       "      <td>2</td>\n",
       "      <td>Decent adventure with some excellent highlights</td>\n",
       "      <td>A decent, well-plotted adventure. I could have...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         polarity                                            title  \\\n",
       "1162981         2                   b- lynch maaaaaaaaaaaaaaaaannn   \n",
       "1347597         1             LOW QUALITY VERY EARLY RECORDINGS!!!   \n",
       "512958          1                          YALL MUST BE KIDDING...   \n",
       "2081008         1                                  surf's up...NOT   \n",
       "1858731         2  Decent adventure with some excellent highlights   \n",
       "\n",
       "                                                    review  \n",
       "1162981  Lynch is back in that ????????? U know what im...  \n",
       "1347597  THIS SHONGS ARE NOT THE GREATEST HITS OF THIS ...  \n",
       "512958   ok first off, if you come by my review, let it...  \n",
       "2081008  The ONLY reason that I gave this game two (2) ...  \n",
       "1858731  A decent, well-plotted adventure. I could have...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f03fd2-cab2-4af5-b4d6-95b25fe3f1bc",
   "metadata": {},
   "source": [
    "### check class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16a71627-559e-417a-bfce-df9f87d94d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polarity\n",
       "2    1800000\n",
       "1    1800000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.polarity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7cc2b7-9cdf-4976-b039-23da7563aed0",
   "metadata": {},
   "source": [
    "No class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2da4f72-f9cd-459f-9064-cab29c440d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing value in review column \n",
    "len(df_train[df_train.review.isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3f2be1-699c-4168-8123-b1b1b995c856",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.review.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2868dc32-dc4b-44f8-888f-6032667b1c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing value in title column \n",
    "len(df_train[df_train.title.isnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e874f7a-f374-4648-a50b-350a9e47d4e5",
   "metadata": {},
   "source": [
    "a 207 NaN value in title, this will create a problem if we planning to combine the title nad review in a single row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03510ed-8cd0-43b2-a360-feec20e4b7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map polarity : positive ->0 | negative -> 1\n",
    "df_train['label'] = df_train.polarity.map({2:0, 1:1})\n",
    "df_train.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fad35bf-0930-45eb-a151-a0a7798ef27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine review title with review body \n",
    "# fillna : replaces any NaN values in the title  an empty string \n",
    "\n",
    "df_train['full_review'] = df_train.title.fillna('') + \" \" + df_train.review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06195f83-f9c3-4b05-80f6-702c19fe5000",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a1cc45-3e66-4e06-b366-385beecc1d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check that the new 'full_review' is not affected by the Nan values in title\n",
    "df_train[df_train.title.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5d37fe-e241-425b-bf8a-12f2b4fd0d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.title[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26daf6dd-62fe-400c-869c-eb8e9242c89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f786bf87-b098-4cf1-a17f-82906814f72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.full_review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8650104d-319c-4f09-8152-ae8c7d17baf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dublicate \n",
    "\n",
    "duplicate_rows = df_train.duplicated() \n",
    "duplicate_rows.any() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eef75be",
   "metadata": {},
   "source": [
    "No Dublicates in the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd5f742-d0de-4a5c-becb-39baa4925729",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train.full_review[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228a75fe-e71f-44a0-85f9-6f139799c0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train.full_review[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa59ea3-3d4b-41d3-9e0a-695200b54e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train.full_review[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8f0507-27d1-43f7-924a-6f12e742d1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check avergae lenght of a full review \n",
    "full_review_avg_length = np.mean([ len(df_train.full_review[0]) for i in range(len(df_train.full_review))])\n",
    "print(full_review_avg_length) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcfa4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for very short reviews \n",
    "\n",
    "short_reviews = df_train[df_train['full_review'].apply(lambda x: len(x.split()) < 10)]\n",
    "\n",
    "short_reviews.label.value_counts()\n",
    "\n",
    "print(f\"Number of short reviews: {len(short_reviews)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f730ad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a36e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_reviews.full_review.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be23a3b",
   "metadata": {},
   "source": [
    "There is a lot of garbage and noise that need our attention "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624c2862-c782-4a8b-8888-00bdbf11f7df",
   "metadata": {},
   "source": [
    "### a random sample of train_df for ease of experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1905fb3a-3272-45da-a7f0-75888e64fa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a lighter df to experiment with \n",
    "df_train_sample  = df_train.sample(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daf02c8-6116-4da0-acad-95acccf63db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_sample.label.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f960c29-53f0-4312-936b-9ead7ab11e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1b3444-7f91-4e3c-a76a-6debe2b8fa16",
   "metadata": {},
   "source": [
    "### Remove URL and HTML tags if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fe320b-fc1a-4bd9-ab9c-b4091df86674",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "has_html_tags = df_train_sample['full_review'].apply(lambda x: bool(BeautifulSoup(x, \"html.parser\").find(True)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a762f4-a615-4338-8157-977b50f06cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_sample[has_html_tags].full_review.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27572d72-d6f9-4169-8803-802d5cfc45b2",
   "metadata": {},
   "source": [
    "there is indeed html tags that will require our attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fe8c8b-a1ca-4d4a-a9f7-6f9a9c09a338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for urls \n",
    "import re\n",
    "has_url = [bool(re.findall(r'http\\S+', df_train_sample.full_review.iloc[i])) for i in range(len(df_train_sample))]\n",
    "df_train_sample[has_url]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa77c79f-dcfd-4ce3-965b-7f52368021f0",
   "metadata": {},
   "source": [
    "both URL and HTML tags do not affect the feeling of the customer, hence they are just noise in our case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b910cd",
   "metadata": {},
   "source": [
    "### Preprocessing Steps:\n",
    "\n",
    "1. **Remove URLs**: Strips any URLs from the review, as they don't contribute meaningfully to sentiment analysis.\n",
    "\n",
    "2. **Remove Gibberish & Excessive Repeated Characters**: Identifies and removes sequences with too many repeated characters (e.g., \"ooooo\" becomes \"o\") and repeated words (e.g., \"great great\" becomes \"great\").\n",
    "\n",
    "3. **Remove Punctuation, Numbers, and Long Words**: Filters out punctuation, numbers, and excessively long words (over 20 characters).\n",
    "\n",
    "4. **Lowercase Text**: Converts all text to lowercase.\n",
    "\n",
    "5. **Remove Stopwords (except \"not\", \"no\", and \"nor\")**: Removes common stopwords except negations to preserve their importance.\n",
    "\n",
    "6. **Lemmatization**: Converts words to their base form (e.g., \"running\" to \"run\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade2b497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load Spacy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# Custom stopwords list to keep \"not\", \"no\", \"nor\"\n",
    "stopwords_to_keep = {\"not\", \"no\", \"nor\"}\n",
    "custom_stopwords = nlp.Defaults.stop_words - stopwords_to_keep\n",
    "\n",
    "# Function to detect gibberish \n",
    "def remove_gibberish(text):\n",
    "    # Remove excessive repeated characters (e.g., 'ooooo' -> 'o')\n",
    "    text = re.sub(r'(.)\\1{3,}', r'\\1', text)\n",
    "    # Remove repeated words (e.g., \"great great\" -> \"great\")\n",
    "    text = re.sub(r'\\b(\\w+)( \\1\\b)+', r'\\1', text)\n",
    "    return text\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # Handle gibberish or repeated patterns\n",
    "    text = remove_gibberish(text)\n",
    "    \n",
    "    # Process with spaCy\n",
    "    doc = nlp(text)\n",
    "\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        # Skip punctuation, digits, or tokens that are excessively long\n",
    "        if token.is_punct or token.is_digit or len(token.text) > 20:\n",
    "            continue\n",
    "        # Skip stopwords except \"not\", \"no\", \"nor\"\n",
    "        if token.text not in custom_stopwords:\n",
    "            # Lemmatize and lowercase valid words\n",
    "            lemma = token.lemma_.lower()\n",
    "            # Keep only valid words\n",
    "            if lemma.isalpha():\n",
    "                tokens.append(lemma)\n",
    "    \n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Combine everything into a pipeline\n",
    "def combined_preprocessing(text_series):\n",
    "    return text_series.apply(preprocess_text)\n",
    "\n",
    "# Create the scikit-learn pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', FunctionTransformer(combined_preprocessing))\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126da23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on short_reviews dataframe \n",
    "cleaned_reviews = pipeline.fit_transform(short_reviews.full_review)\n",
    "print(f' before: {short_reviews.full_review[:1].values} || after: {cleaned_reviews[:1].values} ')\n",
    "print(f' before: {short_reviews.full_review[5:6].values} || after: {cleaned_reviews[5:6].values} ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a4d934",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654799ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadde1a4-65f2-478c-8930-ceb71a4d2557",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbd18f5-a710-4adf-acf8-409963d16c52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
